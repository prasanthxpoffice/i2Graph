{
  "name": "i2graph-llm-proxy",
  "version": "0.1.0",
  "private": true,
  "description": "Secure backend proxy for LLM calls (OpenAI-compatible)",
  "main": "index.js",
  "type": "commonjs",
  "scripts": {
    "start": "node index.js",
    "dev": "node index.js"
  },
  "engines": {
    "node": ">=18.0.0"
  },
  "dependencies": {
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "express": "^4.19.2",
    "express-rate-limit": "^7.1.5",
    "helmet": "^7.1.0"
  }
}

